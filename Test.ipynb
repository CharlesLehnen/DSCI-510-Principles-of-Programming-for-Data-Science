{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33801424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch\n",
    "\n",
    "# Path to the folder containing the image files\n",
    "IMAGE_FOLDER = \"data/images/archived\"\n",
    "\n",
    "# Create lists to hold the paths to the training, validation, and test image sets\n",
    "training_set = []\n",
    "validation_set = []\n",
    "test_set = []\n",
    "\n",
    "# Loop through the files in the image folder\n",
    "for file_name in os.listdir(IMAGE_FOLDER):\n",
    "    # Compute the path to the file\n",
    "    file_path = os.path.join(IMAGE_FOLDER, file_name)\n",
    "\n",
    "    # Add the file to the appropriate set (training, validation, or test)\n",
    "    # based on its name\n",
    "    if \"training\" in file_name:\n",
    "        training_set.append(file_path)\n",
    "    elif \"validation\" in file_name:\n",
    "        validation_set.append(file_path)\n",
    "\n",
    "# Use the function to process the images in the training set\n",
    "training_set_labels = detect_and_classify_animals(training_set)\n",
    "\n",
    "# Use the function to process the images in the validation set\n",
    "validation_set_labels = detect_and_classify_animals(validation_set)\n",
    "\n",
    "        \n",
    "def detect_and_classify_animals(image_paths):\n",
    "    # Load the pre-trained model with the default weights\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(\n",
    "        weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    )\n",
    "\n",
    "    # Create a list to hold the user-provided labels for the detected objects\n",
    "    saved_labels = []\n",
    "\n",
    "    # Loop through the images in the specified folder\n",
    "    for file_path in image_paths:\n",
    "        # Load the image and run it through the model\n",
    "        image = read_image(file_path)\n",
    "        outputs = model(image)\n",
    "\n",
    "        # Extract the bounding boxes and labels for the detected objects\n",
    "        boxes = outputs[0][\"boxes\"].detach().numpy()\n",
    "        labels = outputs[0][\"labels\"].detach().numpy()\n",
    "\n",
    "        # Draw the bounding boxes on the image\n",
    "        image_with_boxes = draw_bounding_boxes(image, boxes)\n",
    "        pil_image = to_pil_image(image_with_boxes)\n",
    "\n",
    "        # Loop through the detected objects and ask the user to classify each one\n",
    "        for box, label in zip(boxes, labels):\n",
    "            print(f\"Please classify the object in bounding box {box}:\")\n",
    "            user_label = input()\n",
    "\n",
    "            # Save the user-provided label for the object\n",
    "            # (You could save this in a file or database for later use)\n",
    "            saved_labels.append({\"box\": box, \"label\": user_label})\n",
    "\n",
    "        # Save the image with the bounding boxes drawn on it\n",
    "        pil_image.save(file_path)\n",
    "\n",
    "    # Return the list of user-provided labels for the detected objects\n",
    "    return saved_labels\n",
    "\n",
    "# Use the function to process the images in the training set\n",
    "training_set_labels = detect_and_classify_animals(training_set)\n",
    "\n",
    "# Use the function to process the images in the validation set\n",
    "validation_set_labels = detect_and_classify_animals(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9901d7b-19e9-461e-abca-f6d529aac3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670642706.6756754\n"
     ]
    }
   ],
   "source": [
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d5953-153b-43c2-8075-af5ea6105370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci_510_final] *",
   "language": "python",
   "name": "conda-env-dsci_510_final-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
